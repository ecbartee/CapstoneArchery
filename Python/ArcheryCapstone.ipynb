{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3accae0-5193-4510-ba2f-4a87efea4c8e",
   "metadata": {},
   "source": [
    "# Archery Capstone\n",
    "This capstone project was created in support of the CodeYou program to showcase the materials covered in the Data Analysis pathway. \n",
    "The code blocks below will walk you through the following:<br>\n",
    "1. Accessing three layers created within ArcGIS Online to collect archery related stats from 3D target events<br>\n",
    "2. Pulling these layers down to data frames to work with separately from the authoritative data within ArcGIS Online<br>\n",
    "3. Cleaning and joining the data so it can be used for futher analysis and graphic creation<br>\n",
    "4. Creating graphics and shot summaries for the archer to reference and analyze for trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12a42b4-1a15-4962-b98f-b03ef26ff703",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "Data was created and collected using esri's ArcGIS Online platform in support of this project. Three distinct layers will be referenced for this project:<br>\n",
    "1.  A lookup table was created containing the various 3D target animals along with information on the color, size, name, and target pattern.<br> \n",
    "2.  A Survey123 was created to collect shoot conditions for each tournament.  Data was collected to capture the shoot name, shoot location (indoor or outdoor), shoes (minimal, hiking boots, sandals, gym shoes), temperature, weather conditions present (sunny, cloudy, humid, windy, foggy, light rain, heavy rain, stormy), and personal conditions (well rested, tired, sick, sore, hungry, full).<br>\n",
    "3.  A Survey123 was created to collect several details for each shot on the individual target and appearance (animal, range, position, elevation, lighting), shot execution (confidence, release details, execution details), and placement (score, aim placement, actual arrow impact). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ac7fe-bc5a-4fc9-9e2f-dc32d7fd1d54",
   "metadata": {},
   "source": [
    "### Import Modules\n",
    "\n",
    "This section imports the various modules required for the code to execute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe1e98-2951-4365-a029-51d3b56e496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayer\n",
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "import os\n",
    "import requests\n",
    "from IPython.display import display\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "print(\"Modules Imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b7c4f-cbd2-431d-b131-b954406724ca",
   "metadata": {},
   "source": [
    "### Download AGOL layers to dataframes\n",
    "\n",
    "This section connects to ArcGIS Online and downloads two of the three datasets to dataframes for cleaning and analysis. The final dataset is then converted to a dataframe from a CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09e805-c945-4e2f-a310-bb50e2419945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to ArcGIS Online\n",
    "# gis = GIS(\"https://sso.maps.arcgis.com/\")\n",
    "gis = GIS()\n",
    "\n",
    "# Define ItemIDs for AGOL layers\n",
    "Shot = \"f0314c505e83428d8ce6894a8d73eb09\"\n",
    "Shoot = \"5fa46f5f47e841b1b2454271cd346d8f\"\n",
    "\n",
    "# Search for the layers by title\n",
    "layer3_Shoot = gis.content.get(Shoot)\n",
    "layer2_Shot = gis.content.get(Shot)\n",
    "#print (layer2_Shot.type)\n",
    "#print (layer3_Shoot.type)\n",
    "\n",
    "# Access the first layer in each item\n",
    "feature_layer2_Shot = layer2_Shot.layers[0]\n",
    "feature_layer3_Shoot = layer3_Shoot.layers[0]\n",
    "# print (feature_layer2_Shot)\n",
    "# print (feature_layer3_Shoot)\n",
    "\n",
    "# Query the layers to get all features\n",
    "features2 = feature_layer2_Shot.query()\n",
    "features3 = feature_layer3_Shoot.query()\n",
    "\n",
    "# Convert features to pandas DataFrames\n",
    "df2_Shot = features2.sdf\n",
    "df3_Shoot = features3.sdf\n",
    "\n",
    "# Read the AnimalLookup CSV to a dataframe\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "data_dir = os.path.join(cwd, \"Data\")\n",
    "print(data_dir)\n",
    "animalLookup_path = f\"{data_dir}\\\\AnimalLookup.csv\"\n",
    "df1_Animal = pd.read_csv(animalLookup_path)\n",
    "\n",
    "print(\"Dataframes imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a229868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that our data has been downloaded to dataframes, let's make sure we are able to see the resulting columns and rows. \n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "# Explore the columns and data of each data frame\n",
    "print(f\"Animal Lookup Dataframe: {df1_Animal.columns}\")\n",
    "display(df1_Animal)\n",
    "print(f\"Shot Report Out Dataframe: {df2_Shot.columns}\")\n",
    "display(df2_Shot)\n",
    "print(f\"Shoot Details: {df3_Shoot.columns}\")\n",
    "display(df3_Shoot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a6f737b-a73c-442a-81ba-c132e4e7f40a",
   "metadata": {},
   "source": [
    "### Combine and clean dataframes using Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2afcf67-020a-48f6-8f8d-d2ac18c73019",
   "metadata": {},
   "source": [
    "1. Populate fields<br>\n",
    "    - Score to Scored Ring<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0c37f-dffa-4a3d-a089-eb2a9d80c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few changes were made to the schema mid data collection - let's clean up some of the columns.  \n",
    "\n",
    "# For the Shot Report Out dataframe, lets cleanup the score column\n",
    "# Set column 'scored_ring' equal to column 'score' where column 'scored_ring' is NaN.  Due to column differences, we need to set the column type as well.\n",
    "df2_Shot['scored_ring'] = df2_Shot['scored_ring'].astype(float)\n",
    "df2_Shot['score'] = df2_Shot['score'].astype(float)\n",
    "df2_Shot['scored_ring'] = df2_Shot['scored_ring'].fillna(df2_Shot['score'])\n",
    "#display(df2_Shot)\n",
    "print(\"Field Updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503d46b",
   "metadata": {},
   "source": [
    "2. Lets combine the three separate dataframes into a single dataframe using the merge function from pandas. This will be done based on common fields and data values between the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a66a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Here are our three dataframes, for reference:  df1_Animal, df2_Shot, df3_Shoot\n",
    "\n",
    "#  First, we will do a merge on df1_Animal to df2_Shot (df1_Animal.TargetName = df2_Shot.target).  Then, we will do another merge between the new dataframe and the df3_Shoot data frame (new.date_and_time = df3_Shoot.date_and_time_of_Shoot) based on the date portion of the datetime fields. \n",
    "\n",
    "# Merge df1_Animal and df2_Shot on 'TargetName' and 'target'\n",
    "merged_df = pd.merge(df2_Shot, df1_Animal,  left_on='target', right_on='Target Name', how='left')\n",
    "#display(merged_df)\n",
    "\n",
    "\n",
    "# Extract the date portion from 'date_and_time' and 'date_and_time_of_Shoot'\n",
    "merged_df['date'] = pd.to_datetime(merged_df['date_and_time']).dt.date\n",
    "df3_Shoot['date'] = pd.to_datetime(df3_Shoot['date_and_time_of_shoot']).dt.date\n",
    "\n",
    "# Merge the resulting DataFrame with df3_Shoot on the date portion of the datetime strings\n",
    "final_merged_df = pd.merge(merged_df, df3_Shoot, on='date', how='inner')\n",
    "\n",
    "# # Drop the extra 'date' column\n",
    "final_merged_df.drop(columns=['date'], inplace=True)\n",
    "#display(final_merged_df)\n",
    "\n",
    "print(\"Dataframes merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e4d87-d1d7-41fb-81f0-3f5e63a9647a",
   "metadata": {},
   "source": [
    "3. Clean dataframes using pandas\n",
    "<p>The survey123 mobile applications used to collect information on the overall shoot details and shot report out used functionality called \"Multi-Select\" fields.  This meant the archer was able to select multiple values for a single question if the values were all relevant, streamlining the data entry process. For example, when recording the position of the animal, the archer could select if it was Quartered_to, Quartered_From, Broadside, Leaning_Forward, or Leaning_Back - all from the same question.  </p>\n",
    "\n",
    "<p>When multiple answers are selected, the survey concatenates the answers into a string in a single field.  In order to perform analysis on the recorded values for the multi-select fields, we need to break out and add unique columns to our data frames.  To do this, we'll create new columns in our merged dataframe and use string operations to populate the columns based on the values present in the concatenated fields.</p>\n",
    "\n",
    "Create flag fields on the multi-select questions below:\n",
    "-  Adjustment (adjustment)\n",
    "    -  Increase_Yardage, Decrease_Yardage, Sight_Left, Sight_Right\n",
    "-  Position (position)\n",
    "    -  Quartered_to, Quartered_From, Broadside, Leaning_Forward, Leaning_Back\n",
    "-  Shot Placement (shot_placement)\n",
    "    -  On_Aim_Point, High, Low, Left, Right, Miss, Kick_Out\n",
    "-  Shot Execution (shot_execution)\n",
    "    -  Unsure, Felt_Good, Bad_Shoulder, Bad_Release, Movement_in_Shot, Unable_to_Center_Bubble, Dip, Push_Up, Glare, other\n",
    "-  Release Details (release_details)\n",
    "    -  Too_Soon, Fast, Slow, Off_Face, Hand_Moved\n",
    "-  Weather Conditions Present (weather_conditions_present)\n",
    "    -  Sunny, Cloudy, Humid, Windy, Foggy, Light_Rain, Heavy_Rain, Stormy\n",
    "-  Personal Conditions (personal_conditions)\n",
    "    -  Well_Rested, Tired, Sick, Sore, Hungry, Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86999403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the values to check\n",
    "position = ['Quartered_to','Quartered_From','Broadside','Leaning_Forward','Leaning_Back']\n",
    "shot_placement = ['On_Aim_Point','High','Low','Left','Right','Miss, Kick_Out']\n",
    "shot_execution = ['Unsure','Felt_Good','Bad_Shoulder','Bad_Release','Movement_in_Shot','Unable_to_Center_Bubble','Dip','Push_Up','Glare','other']\n",
    "release_details = ['Too_Soon','Fast','Slow','Off_Face','Hand_Moved']\n",
    "weather_conditions_present = ['Sunny','Cloudy','Humid','Windy','Foggy','Light_Rain','Heavy_Rain','Stormy']\n",
    "personal_conditions = ['Well_Rested','Tired','Sick','Sore','Hungry','Full']\n",
    "\n",
    "# Function to create new columns based on values in a specific column\n",
    "def create_columns_based_on_values(df, column_name, values_list):\n",
    "    if column_name in df.columns:\n",
    "        for value in values_list:\n",
    "            #df[value] = df[column_name].apply(lambda x: 1 if value in x else 0)\n",
    "            df[value] = df[column_name].fillna('').apply(lambda x: 1 if value in x else 0)\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' does not exist in the DataFrame.\")\n",
    "\n",
    "# Create new columns for each category\n",
    "create_columns_based_on_values(final_merged_df, 'shot_execution', shot_execution)\n",
    "create_columns_based_on_values(final_merged_df, 'position', position)\n",
    "create_columns_based_on_values(final_merged_df, 'release_details', release_details)\n",
    "create_columns_based_on_values(final_merged_df, 'shot_placement', shot_placement)\n",
    "create_columns_based_on_values(final_merged_df, 'weather_conditions_present', weather_conditions_present)\n",
    "create_columns_based_on_values(final_merged_df, 'personal_conditions', personal_conditions)\n",
    "\n",
    "\n",
    "# Drop columns not useful within analysis and graph creation:\n",
    "#print(f\"Final Dataframe pre-drop: {final_merged_df.columns}\")\n",
    "final_merged_df.drop(columns=['globalid_x', 'CreationDate_x', 'Creator_x','target_order','untitled_question_3_other', 'score', 'adjustment_made', 'adjustment','SHAPE_x', 'OBJECTID','objectid_y', 'globalid_y', 'CreationDate_y','Creator_y', 'EditDate_y', 'Editor_y','SHAPE_y'], inplace=True)\n",
    "#print(f\"Final Dataframe post-drop: {final_merged_df.columns}\")\n",
    "\n",
    "display(final_merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f68e7-f663-490c-9c65-9fdac214fefc",
   "metadata": {},
   "source": [
    "### Create graphics from shooting statistics\n",
    "The code block below will create a dashboard where you can compare any two variables within the dataframe to see graphs and patterns.  Below are recommendations to try - as well as what they mean. \n",
    "- Target and range, Violin graph type\n",
    "    - Shows the spread of ranges the different animals are typically placed at.  \n",
    "- Target Size and range, Scatter graph type\n",
    "    - Shows the spread of ranges a target is typically placed at - from this graph you can see the medium sized targets are normally placed outside of 33 yards. \n",
    "- aim_placement and range, scatter\n",
    "    - Shows the archers spread of aiming at the center of the ten ring or the lower 12 as the range increases.\n",
    "- Shot-placement on aim_placement, histogram, count\n",
    "    - This shows how often the archer hit what they were aiming at - in this graph trends can be seen that indicate the archer was either on target or high and left.\n",
    "- Slow on Target Size, Bar, Sum\n",
    "    -  This graph indicates the archer may be holding longer on big targets which causes a slow release and more movement in the shot. \n",
    "- range and date_and_time_of_shoot, box, count\n",
    "    - This graph shows the average spread of ranges at the four events records were collected at. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2053d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_merged_df\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Layout of the Dash app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Interactive Data Visualization\", style={'color': 'teal'}),\n",
    "    html.Label(\"Choose X-axis variable\", style={'color': 'green', 'font-weight': 'bold'}),\n",
    "    dcc.Dropdown(\n",
    "        id='x-axis',\n",
    "        options=[{'label': col, 'value': col} for col in df.columns],\n",
    "        value=df.columns[0]\n",
    "    ),\n",
    "    html.Label(\"Choose Y-axis variable\", style={'color': 'green', 'font-weight': 'bold'}),\n",
    "    dcc.Dropdown(\n",
    "        id='y-axis',\n",
    "        options=[{'label': col, 'value': col} for col in df.columns],\n",
    "        value=df.columns[1]\n",
    "    ),\n",
    "    html.Label(\"Choose graph type\", style={'color': 'beige', 'font-weight': 'bold'}),\n",
    "    dcc.Dropdown(\n",
    "        id='graph-type',\n",
    "        options=[\n",
    "            {'label': 'Scatter', 'value': 'scatter'},\n",
    "            {'label': 'Line', 'value': 'line'},\n",
    "            {'label': 'Bar', 'value': 'bar'},\n",
    "            {'label': 'Histogram', 'value': 'histogram'},\n",
    "            {'label': 'Box', 'value': 'box'},\n",
    "            {'label': 'Violin', 'value': 'violin'},\n",
    "            {'label': 'Pie', 'value': 'pie'},\n",
    "            {'label': 'Density Heatmap', 'value': 'density_heatmap'},\n",
    "            {'label': 'Density Contour', 'value': 'density_contour'}\n",
    "        ],\n",
    "        value='scatter'\n",
    "    ),\n",
    "    html.Label(\"Aggregation Function (only for applicable graphs)\", style={'color': 'beige'}),\n",
    "    dcc.Dropdown(\n",
    "        id='agg-func',\n",
    "        options=[\n",
    "            {'label': 'Sum', 'value': 'sum'},\n",
    "            {'label': 'Count', 'value': 'count'}\n",
    "        ],\n",
    "        value='sum'\n",
    "    ),\n",
    "    dcc.Graph(id='graph')\n",
    "])\n",
    "\n",
    "# Callback to update graph based on user input\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),\n",
    "    [Input('x-axis', 'value'), Input('y-axis', 'value'), Input('graph-type', 'value'), Input('agg-func', 'value')]\n",
    ")\n",
    "def update_graph(x_axis, y_axis, graph_type, agg_func):\n",
    "    if graph_type == 'scatter':\n",
    "        fig = px.scatter(df, x=x_axis, y=y_axis)\n",
    "    elif graph_type == 'line':\n",
    "        fig = px.line(df, x=x_axis, y=y_axis)\n",
    "    elif graph_type == 'bar':\n",
    "        if agg_func == 'sum':\n",
    "            fig = px.bar(df, x=x_axis, y=y_axis)\n",
    "        elif agg_func == 'count':\n",
    "            fig = px.bar(df, x=x_axis, y=df.groupby(x_axis)[y_axis].transform('count'))\n",
    "    elif graph_type == 'histogram':\n",
    "        if agg_func == 'sum':\n",
    "            fig = px.histogram(df, x=x_axis, y=y_axis)\n",
    "        elif agg_func == 'count':\n",
    "            fig = px.histogram(df, x=x_axis)\n",
    "    elif graph_type == 'box':\n",
    "        fig = px.box(df, x=x_axis, y=y_axis)\n",
    "    elif graph_type == 'violin':\n",
    "        fig = px.violin(df, x=x_axis, y=y_axis)\n",
    "    elif graph_type == 'pie':\n",
    "        fig = px.pie(df, names=x_axis, values=y_axis)\n",
    "    elif graph_type == 'funnel':\n",
    "        fig = px.funnel(df, x=x_axis, y=y_axis)\n",
    "    elif graph_type == 'density_heatmap':\n",
    "        fig = px.density_heatmap(df, x=x_axis, y=y_axis)\n",
    "    elif graph_type == 'density_contour':\n",
    "        fig = px.density_contour(df, x=x_axis, y=y_axis)\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d7b595-52a3-4f6a-9dbc-bd3cf11a69b6",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "1.  Identify further parameters for performing analysis\n",
    "2.  Fine tune the shoot report mobile survey to collect additional informatiton (i.e. which direction is the target facing), populate defaults, improve the data entry process, and allow for open ranges / judging. \n",
    "3.  Create a PDF or Word Report for daily shoot summaries\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
